---
title: "bibsearch"
format: html
editor: visual
---

```{r}
#| label: setup
library(tidyverse)
library(magrittr, include.only = "%<>%")
library(conflicted)

# maintain consistency -- within limits of implementation -- across databases

query.ls <- list(
           OR_terms = c("preprint","peer","preregistraton","FAIR"),
           AND_terms = c("open science"),
           NOT_terms = c("quahog","aardvark"),
           FROM_date = as.Date("2019-01-1"),
           UNTIL_date = as.Date("2024-12-30"),
           MAX_results = 400,
           EMAIL_str = "foo@bar.com"
           )

```

**Initial search**

```{r}
#| label: crossref-search

requireNamespace("rcrossref")

#Crossref provides a mechanism to supply api-keys -- or to self-identify in order to enter the 'polite' pool of queries

Sys.setenv(crossref_email= query.ls[["EMAIL_str"]])

## crossref supports simple queries, terms are OR'ed together; can be filtered for time + publication
## See: https://api.crossref.org/swagger-ui/index.html#/Works/get_works

crossref_query <- 
  glue::glue_collapse(
            glue::glue('"{x}"',
                       x= c(query.ls[["OR_terms"]],query.ls[["AND_terms"]])),
            sep="+")

crossref_response.ls <- 
  rcrossref::cr_works(
        sort="score",
        order="asc",
        filter=c("from_update_date"=as.character(query.ls[["FROM_date"]]),
                 "until_update_date"=as.character(query.ls[["UNTIL_date"]]),
                 "type"="book-chapter",
                 "type"="journal-article"
                ),
        query = crossref_query,          ,
        limit=1000,
        cursor="*",
        cursor_max=query.ls[["MAX_results"]]
  )

crossref_results.df <- crossref_response.ls[["data"]]

rm(crossref_query)
```

```{r more-searches}
#| label: openalex-search

options(openalexR.mailto = query.ls[["EMAIL_str"]])
requireNamespace("openalexR")

openalex_query_str <-
  glue::glue('{x_and} {x_not} ({x_or})',
              x_or = glue::glue_collapse(
               glue::glue('"{x}"', x= query.ls[["OR_terms"]]),
               sep=" OR "),
              x_and = glue::glue_collapse(
               glue::glue('"{x}"', x = query.ls[["AND_terms"]]),
               sep=" AND "),
              x_not = glue::glue_collapse(
               glue::glue('NOT "{x}"', x = 
                            c(query.ls[["NOT_terms"]])),
                          ,
               sep=" "),
             
  )

openalex_query <- openalexR::oa_query(
  entity = "works",
  title_and_abstract.search = openalex_query_str,
  from_publication_date = as.character(query.ls[["FROM_date"]]),
  to_publication_date = as.character(query.ls[["UNTIL_date"]]),
  options = list(sort = "relevance_score:desc"),
  verbose=TRUE
)


# see https://docs.openalex.org/how-to-use-the-api
openalex_response.ls <- openalexR::oa_request(
  query_url = openalex_query,
  paging = "cursor",
  per_page = 200,
  pages=seq.int(from=1,to=max(1,query.ls[["MAX_results"]]/200)),
  verbose = TRUE,
)

openalex_results.df <- openalexR::oa2df(openalex_response.ls, entity = "works")

rm(openalex_query, openalex_query_str)
```

**Post-process**

```{r}
#| label: merge-records

postFilter <- function(x, textfield,  filter.ls) {
  # TEST CASE
  # tibble(fruit) %>% mutate(i=row_number()) %>%
  #  postFilter(fruit, filter.ls =
  #  list(OR_terms=c("blue","black"),AND_terms=c("berry","err"),NOT_terms="straw"))
  
  res <-
     x %>%
       dplyr::filter(!stringr::str_detect({{textfield}}, 
          glue::glue_collapse(filter.ls[["NOT_terms"]], sep="|")
      ))
  
  res %<>% 
     dplyr::filter(stringr::str_detect({{textfield}}, 
        glue::glue_collapse(c(filter.ls[["OR_terms"]],filter.ls[["AND_terms"]]),
                            sep="|")
     ))
  
  for (i in filter.ls[["AND_terms"]]) {
    res %<>% 
      dplyr::filter(str_detect({{textfield}},i))
  }

  res
}

merged_min.df <-
  crossref_results.df %>% 
  select(doi, container.title, title, type, abstract, 
         pubdate = published.online ) %>%
  mutate(type = 
           case_match( 
             type,
             c("journal-article") ~ "article",
             .default = type
           ),
         pubdate = lubridate::as_date(pubdate)
  )

merged_min.df %<>% bind_rows(
  openalex_results.df %>%
    select(doi, container.title = so, title, type, abstract=ab, 
           pubdate=publication_date) %>%
    mutate(type = 
           case_match( 
             type,
             c("journal-article") ~ "article",
             .default = type
           ),
         pubdate = lubridate::as_date(pubdate)
  )
)

# drop duplicate DOI's

merged_min.df %<>%
  group_by(doi) %>%
  slice_head(n=1) %>%
  ungroup()
  

merged_min.df %<>%
  dplyr::filter(type %in% c("article","book-chapter","preprint","review"))

# postfilter cross-ref

merged_min.df %<>% mutate(allMtext =
                           glue::glue("{x} {y}", x=title, y=abstract))

merged_min.df %<>% 
  postFilter(allMtext, filter.ls = query.ls)
```

**Export bibliography for zotero**

```{r}
#| label: export records

requireNamespace("RefManageR")
requireNamespace("bib2df")

bib.ls <- merged_min.df %>% 
  mutate(YEAR = lubridate::year(pubdate),
         CATEGORY = case_match(type, .default="MISC",
                c("article") ~ "ARTICLE",
                c("book-chapter") ~ "IN-COLLECTION",
                c("preprint") ~ "MISC"
                )
           ) %>%
  select(CATEGORY=type,TITLE=title, DOI=doi, JOURNAL=container.title) %>%
  bib2df::df2bib()



```

**Todo:**

-   doublecheck false positives (based on `postFilter` vs. `openAlex`

-   explore search term generation using `litsearchr`

-   forward citation snowballing

-   Lens / Dimensions searching using `dimensionsR` , `citationchaser`

-   export counts for (parts of) PRISMA chart

-   pull coding spreadsheet from gdrive for PRISMA charting and descriptives

-   push to Zotero
